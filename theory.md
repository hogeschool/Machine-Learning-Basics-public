**Note: The course will be given in Dutch**
**Note: Some of the subjects might be changed or removed during the first iteration of the course for plannning purposes**

## Theory

### Basic Datastructures and recap** 

- Introduction to Complexity Analysis 

- Standard datatypes: List, Tuple, Dictionary, Set, Queue, Stack, Linked List 

- Memory comparison between different data structures

## Working with numpy

- Numpy basics 

- Doing calculations with arrays/matrices 

- Numpy functions 

- Dot product   

- Exploring data

- Visualizing data


## Graphs and Trees

- Graphs, Trees 

- Complexity of these. 

- Search by BFS, DFS 

- Shortest Path algorithms: Dijkstra, A* 

- Tree representations with different data structures 



**4. Data representation**

- Categorical vs Continuous data 

- One hot encoding 

- Other representations of different kinds of data

 

## Unsupervised learning

- Difference between Supervised and Unsupervised learning 

- Examples and applications of Unsupervised learning 

- Principal Component Analysis 

- K-means clustering 

 

## Supervised Learning

- Supervised learning applications 

- Regression vs Classification 

- Dicision trees 

- Linear regression 

- Introduction to deep learning 

- Test/training set explanation 

- KNN algorithm 



### Neural Networks Introduction**

- Purpose 

- Introduction to global architecture: Layers, weights, bias etc 

- Forward step 

- Data representation

 

### Architecture and data for the NN** 

- Architecture in more detail, why certain choices are made (eg layers, nodes etc.) 

- Introduction to epochs, accuracy and loss 

- Predictions and Evaluations 

- Explanation of using a library to create a simple NN and how to experiment with it 

- Epochs

- Datastructure sizes in NN


### Activation functions** 

- Forward propagation 

- activation functions: Relu, Sigmoid, Softmax 

- Different datastructures and algorithms for a library independent NN 

 

### Back propagation** 

- Basic explanation and purpose 

- Gradient 

- Derivative of activation functions 

- Cross-entropy loss 

- Loss derivative 

- Learning rate 

- Backpropagation in depth pseudocode 
 

### Train and predict

- Bringing it all together

### Decision Trees

- TBD

**Optional subjects**

- Transformer

- Attention

- Convolution

- etc

